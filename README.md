# Ollama-With-Voice

Bring your local LLMs to life with voice interaction!

Ollama-With-Voice is a Python-based project that integrates Ollama with Piper to create a seamless, real-time voice interface for your locally hosted Large Language Models (LLMs). This allows you to interact with your AI assistant using natural speech and receive spoken responses, all running entirely offline.

Features:
Voice-Enabled LLM Interaction: Speak your queries and hear responses from your Ollama-powered models.

Real-time Audio Processing: Utilizes Piper for high-quality, real-time, and efficient text-to-speech (TTS) conversion.

Local and Private: All processing happens on your machine, ensuring data privacy and offline functionality.

Web Interface: Access the interactive voice agent through a user-friendly web interface (http://localhost:3000).

Configurable API Endpoints: Easily customize Ollama and Piper API URLs within the ollama.py script.

Transform your local LLM experience into an engaging, conversational assistant. Get started today and talk to your AI!
